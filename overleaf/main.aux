\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\abx@aux@refcontext{nyt/global//global/global}
\babel@aux{english}{}
\abx@aux@cite{0}{hays2008im2gps}
\abx@aux@segm{0}{0}{hays2008im2gps}
\abx@aux@cite{0}{li2020visual}
\abx@aux@segm{0}{0}{li2020visual}
\abx@aux@cite{0}{astruc2024omniloc}
\abx@aux@segm{0}{0}{astruc2024omniloc}
\abx@aux@cite{0}{hays2008im2gps}
\abx@aux@segm{0}{0}{hays2008im2gps}
\abx@aux@cite{0}{weyand2016planet}
\abx@aux@segm{0}{0}{weyand2016planet}
\abx@aux@cite{0}{muller2018geolocation}
\abx@aux@segm{0}{0}{muller2018geolocation}
\abx@aux@cite{0}{seo2018cpl}
\abx@aux@segm{0}{0}{seo2018cpl}
\abx@aux@cite{0}{haas2024pigeon}
\abx@aux@segm{0}{0}{haas2024pigeon}
\abx@aux@cite{0}{radford2021learning}
\abx@aux@segm{0}{0}{radford2021learning}
\abx@aux@cite{0}{streetclip2023}
\abx@aux@segm{0}{0}{streetclip2023}
\abx@aux@cite{0}{cepeda2023geoclip}
\abx@aux@segm{0}{0}{cepeda2023geoclip}
\abx@aux@cite{0}{koh2020concept}
\abx@aux@segm{0}{0}{koh2020concept}
\abx@aux@cite{0}{hays2008im2gps}
\abx@aux@segm{0}{0}{hays2008im2gps}
\abx@aux@cite{0}{weyand2016planet}
\abx@aux@segm{0}{0}{weyand2016planet}
\abx@aux@cite{0}{s2geometry}
\abx@aux@segm{0}{0}{s2geometry}
\abx@aux@cite{0}{muller2018geolocation}
\abx@aux@segm{0}{0}{muller2018geolocation}
\abx@aux@cite{0}{seo2018cpl}
\abx@aux@segm{0}{0}{seo2018cpl}
\abx@aux@cite{0}{streetclip2023}
\abx@aux@segm{0}{0}{streetclip2023}
\abx@aux@cite{0}{cepeda2023geoclip}
\abx@aux@segm{0}{0}{cepeda2023geoclip}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{2}{Introduction}{section.1}{}}
\abx@aux@page{1}{2}
\abx@aux@page{2}{2}
\abx@aux@page{3}{2}
\abx@aux@page{4}{2}
\abx@aux@page{5}{2}
\abx@aux@page{6}{2}
\abx@aux@page{7}{2}
\abx@aux@page{8}{2}
\abx@aux@page{9}{2}
\abx@aux@page{10}{2}
\abx@aux@page{11}{2}
\abx@aux@page{12}{2}
\abx@aux@cite{0}{koh2020concept}
\abx@aux@segm{0}{0}{koh2020concept}
\abx@aux@cite{0}{yuksekgonul2022posthoc}
\abx@aux@segm{0}{0}{yuksekgonul2022posthoc}
\abx@aux@cite{0}{vandenhirtz2024stochastic}
\abx@aux@segm{0}{0}{vandenhirtz2024stochastic}
\abx@aux@cite{0}{chauhan2023interactive}
\abx@aux@segm{0}{0}{chauhan2023interactive}
\abx@aux@cite{0}{radford2021learning}
\abx@aux@segm{0}{0}{radford2021learning}
\abx@aux@cite{0}{cepeda2023geoclip}
\abx@aux@segm{0}{0}{cepeda2023geoclip}
\abx@aux@cite{0}{toker2021satellite_cvpr}
\abx@aux@segm{0}{0}{toker2021satellite_cvpr}
\abx@aux@cite{0}{bengio2009curriculum}
\abx@aux@segm{0}{0}{bengio2009curriculum}
\abx@aux@cite{0}{geoguessr}
\abx@aux@segm{0}{0}{geoguessr}
\abx@aux@cite{0}{learnablemeta}
\abx@aux@segm{0}{0}{learnablemeta}
\abx@aux@cite{0}{s2geometry}
\abx@aux@segm{0}{0}{s2geometry}
\abx@aux@cite{0}{biljecki2021street}
\abx@aux@segm{0}{0}{biljecki2021street}
\abx@aux@cite{0}{wang2025street}
\abx@aux@segm{0}{0}{wang2025street}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{3}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{3}{Related Work}{section.2}{}}
\abx@aux@page{13}{3}
\abx@aux@page{14}{3}
\abx@aux@page{15}{3}
\abx@aux@page{16}{3}
\abx@aux@page{17}{3}
\abx@aux@page{18}{3}
\abx@aux@page{19}{3}
\abx@aux@page{20}{3}
\abx@aux@page{21}{3}
\abx@aux@page{22}{3}
\abx@aux@page{23}{3}
\abx@aux@page{24}{3}
\abx@aux@page{25}{3}
\abx@aux@page{26}{3}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{3}{section.3}\protected@file@percent }
\newlabel{sec:methodology}{{3}{3}{Methodology}{section.3}{}}
\abx@aux@page{27}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dataset and Preprocessing}{3}{subsection.3.1}\protected@file@percent }
\abx@aux@page{28}{3}
\abx@aux@page{29}{3}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Three-stage architecture for concept-aware geolocation. Stage 0 performs domain contrastive pretraining to align image, GPS, and concept embeddings, with a GPS adapter (512d$\to $768d) to align GeoCLIP location features with StreetCLIP image features. Stage 1 learns hierarchical concept classification through text-anchored prototypes with cosine similarity. Stage 2 predicts geographic coordinates via learned gated fusion: concept embeddings query image patches through cross-attention to extract spatial context, then a learned gate balances concept versus spatial information for each dimension.\relax }}{4}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:architecture}{{1}{4}{Three-stage architecture for concept-aware geolocation. Stage 0 performs domain contrastive pretraining to align image, GPS, and concept embeddings, with a GPS adapter (512d$\to $768d) to align GeoCLIP location features with StreetCLIP image features. Stage 1 learns hierarchical concept classification through text-anchored prototypes with cosine similarity. Stage 2 predicts geographic coordinates via learned gated fusion: concept embeddings query image patches through cross-attention to extract spatial context, then a learned gate balances concept versus spatial information for each dimension.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Geocell Generation}{4}{subsection.3.2}\protected@file@percent }
\abx@aux@page{30}{4}
\abx@aux@page{31}{4}
\abx@aux@page{32}{4}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Stage 0: Domain Contrastive Pretraining}{4}{subsection.3.3}\protected@file@percent }
\abx@aux@cite{0}{oord2018infonce}
\abx@aux@segm{0}{0}{oord2018infonce}
\newlabel{fig:geocells_map}{{2a}{5}{Voronoi tessellation of geocells showing cell centers (red markers) and their boundaries. Cell density adapts to regional data availability.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:geocells_map}{{a}{5}{Voronoi tessellation of geocells showing cell centers (red markers) and their boundaries. Cell density adapts to regional data availability.\relax }{figure.caption.3}{}}
\newlabel{fig:geocells_dist}{{2b}{5}{Distribution of geocells by latitude (left) and hemisphere (right), showing concentration in northern populated regions.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:geocells_dist}{{b}{5}{Distribution of geocells by latitude (left) and hemisphere (right), showing concentration in northern populated regions.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Adaptive geocell generation through per-country K-means clustering in 3D Cartesian space. The 1,048 geocells provide finer granularity in data-dense regions while maintaining global coverage.\relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:geocells}{{2}{5}{Adaptive geocell generation through per-country K-means clustering in 3D Cartesian space. The 1,048 geocells provide finer granularity in data-dense regions while maintaining global coverage.\relax }{figure.caption.3}{}}
\abx@aux@page{33}{5}
\abx@aux@cite{0}{lin2017focal}
\abx@aux@segm{0}{0}{lin2017focal}
\abx@aux@cite{0}{loshchilov2017adamw}
\abx@aux@segm{0}{0}{loshchilov2017adamw}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Stage 1: Text-Prototype Concept Learning}{6}{subsection.3.4}\protected@file@percent }
\abx@aux@page{34}{6}
\abx@aux@page{35}{6}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Stage 2: Gated Fusion Geolocation}{6}{subsection.3.5}\protected@file@percent }
\abx@aux@cite{0}{vaswani2017attention}
\abx@aux@segm{0}{0}{vaswani2017attention}
\abx@aux@page{36}{7}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{7}{section.4}\protected@file@percent }
\newlabel{sec:experiments}{{4}{7}{Experiments}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Evaluation Metrics}{8}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Stage 1: Concept Classification Results}{8}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Stage 1 concept classification accuracy (\%) on the test split. The finetuned variant with Stage 0 pretraining shows improved parent concept accuracy, indicating better hierarchical structure learning.\relax }}{8}{table.caption.4}\protected@file@percent }
\newlabel{tab:stage1}{{1}{8}{Stage 1 concept classification accuracy (\%) on the test split. The finetuned variant with Stage 0 pretraining shows improved parent concept accuracy, indicating better hierarchical structure learning.\relax }{table.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Stage 2: Geolocation Results}{8}{subsection.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Stage 2 geolocation performance on the in-distribution test split. The finetuned variant with gated fusion (``both'') achieves the best median error of 126 km by adaptively combining concept and spatial information.\relax }}{8}{table.caption.5}\protected@file@percent }
\newlabel{tab:stage2_test}{{2}{8}{Stage 2 geolocation performance on the in-distribution test split. The finetuned variant with gated fusion (``both'') achieves the best median error of 126 km by adaptively combining concept and spatial information.\relax }{table.caption.5}{}}
\abx@aux@cite{0}{fren-gor-geoguessr}
\abx@aux@segm{0}{0}{fren-gor-geoguessr}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Out-of-Distribution Evaluation}{9}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}External GeoGuessr Dataset Evaluation}{9}{subsubsection.4.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Stage 2 geolocation performance on the external HuggingFace GeoGuessr dataset. Performance degrades compared to in-distribution data, with the finetuned variant showing better generalization.\relax }}{9}{table.caption.6}\protected@file@percent }
\newlabel{tab:stage2_hf}{{3}{9}{Stage 2 geolocation performance on the external HuggingFace GeoGuessr dataset. Performance degrades compared to in-distribution data, with the finetuned variant showing better generalization.\relax }{table.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}GeoGuessr Game Evaluation}{10}{subsubsection.4.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces GeoGuessr game comparison: model vs human performance on 25 live rounds.\relax }}{10}{table.caption.7}\protected@file@percent }
\newlabel{tab:human_comparison}{{4}{10}{GeoGuessr game comparison: model vs human performance on 25 live rounds.\relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Interpretability Analysis}{10}{subsection.4.5}\protected@file@percent }
\newlabel{sec:interpretability}{{4.5}{10}{Interpretability Analysis}{subsection.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Distribution of learned gate values during validation. The gate controls the contribution of concept versus spatial (cross-attention) information for each of the 512 dimensions. Higher values (near 1) indicate greater reliance on concept information, while lower values (near 0) indicate greater reliance on spatial image features. The model learns to use a balanced combination, with median gate value around 0.58, though dimensions vary widely from concept-dominated (90th percentile: 0.82) to spatial-dominated (10th percentile: 0.29).\relax }}{10}{figure.caption.8}\protected@file@percent }
\newlabel{fig:gate_distribution}{{3}{10}{Distribution of learned gate values during validation. The gate controls the contribution of concept versus spatial (cross-attention) information for each of the 512 dimensions. Higher values (near 1) indicate greater reliance on concept information, while lower values (near 0) indicate greater reliance on spatial image features. The model learns to use a balanced combination, with median gate value around 0.58, though dimensions vary widely from concept-dominated (90th percentile: 0.82) to spatial-dominated (10th percentile: 0.29).\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{11}{section.5}\protected@file@percent }
\newlabel{sec:discussion}{{5}{11}{Discussion}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{12}{section.6}\protected@file@percent }
\newlabel{sec:conclusion}{{6}{12}{Conclusion}{section.6}{}}
\abx@aux@page{37}{12}
\abx@aux@page{38}{12}
\abx@aux@page{39}{12}
\abx@aux@page{40}{12}
\abx@aux@page{41}{12}
\abx@aux@page{42}{12}
\abx@aux@page{43}{12}
\abx@aux@page{44}{12}
\abx@aux@page{45}{12}
\abx@aux@page{46}{12}
\abx@aux@page{47}{12}
\abx@aux@page{48}{12}
\abx@aux@page{49}{12}
\abx@aux@page{50}{12}
\abx@aux@page{51}{13}
\abx@aux@page{52}{13}
\abx@aux@page{53}{13}
\abx@aux@page{54}{13}
\abx@aux@page{55}{13}
\abx@aux@page{56}{13}
\abx@aux@page{57}{13}
\abx@aux@page{58}{13}
\abx@aux@page{59}{13}
\abx@aux@page{60}{13}
\abx@aux@page{61}{13}
\@writefile{toc}{\contentsline {section}{\numberline {A}Detailed Interpretability Examples}{13}{appendix.A}\protected@file@percent }
\newlabel{app:interpretability}{{A}{13}{Detailed Interpretability Examples}{appendix.A}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Interpretability analysis for Game 1 Round 1. This example demonstrates the model attending to architectural and infrastructure features for geolocation. The patch attention heatmap reveals focus on road geometry and built structures, while concept predictions capture semantic categories relevant to the predicted region.\relax }}{14}{figure.caption.10}\protected@file@percent }
\newlabel{fig:interpretability_example_b}{{4}{14}{Interpretability analysis for Game 1 Round 1. This example demonstrates the model attending to architectural and infrastructure features for geolocation. The patch attention heatmap reveals focus on road geometry and built structures, while concept predictions capture semantic categories relevant to the predicted region.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Interpretability analysis for Game 1 Round 9. The model identifies this location in West Africa through distinctive visual cues including unique vehicles and license plates, with balanced concept-spatial reasoning (gate 0.431). Top child concepts include ``Unique car'' and ``License Plates''; parent concepts indicate ``car\_meta'' and ``landscape\_savannah'' categories.\relax }}{15}{figure.caption.11}\protected@file@percent }
\newlabel{fig:interpretability_example_a}{{5}{15}{Interpretability analysis for Game 1 Round 9. The model identifies this location in West Africa through distinctive visual cues including unique vehicles and license plates, with balanced concept-spatial reasoning (gate 0.431). Top child concepts include ``Unique car'' and ``License Plates''; parent concepts indicate ``car\_meta'' and ``landscape\_savannah'' categories.\relax }{figure.caption.11}{}}
\newlabel{LastPage}{{}{15}{}{page.15}{}}
\xdef\lastpage@lastpage{15}
\xdef\lastpage@lastpageHy{15}
\abx@aux@read@bbl@mdfivesum{76D8AE366BC9647F5CBC68FB029A8422}
\abx@aux@defaultrefcontext{0}{geoguessr}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{astruc2024omniloc}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{bengio2009curriculum}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{biljecki2021street}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{chauhan2023interactive}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{streetclip2023}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{haas2024pigeon}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{hays2008im2gps}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{s2geometry}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{koh2020concept}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{learnablemeta}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{li2020visual}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{lin2017focal}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{loshchilov2017adamw}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{muller2018geolocation}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{oord2018infonce}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{radford2021learning}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{seo2018cpl}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{toker2021satellite_cvpr}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{vandenhirtz2024stochastic}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{vaswani2017attention}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{cepeda2023geoclip}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{wang2025street}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{weyand2016planet}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{yuksekgonul2022posthoc}{nyt/global//global/global}
\gdef \@abspage@last{15}
